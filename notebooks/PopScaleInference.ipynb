{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/.venv/lib/python3.9/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.AreaCalc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTraits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m area_calc\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSegmentImage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mSegmentImage\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMeasure\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mMeasure\u001b[39;00m\n\u001b[1;32m     28\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(GetLowestGPU(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/mnt/DGX01/Personal/krusepi/codebase/projects/phenotyping/PennycressUNet/notebooks/../utils/Measure.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTileGenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TileGenerator\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m iou\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAreaCalc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m area_calc\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSegmentImage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mSegmentImage\u001b[39;00m\n\u001b[1;32m     32\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(GetLowestGPU(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.AreaCalc'"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from ipywidgets import FloatProgress\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from importlib import reload\n",
    "\n",
    "# append path\n",
    "sys.path.append('../')\n",
    "\n",
    "# custom\n",
    "from utils.BuildUNet import UNet\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "from utils.TileGenerator import TileGenerator\n",
    "from utils.Metrics import iou\n",
    "from utils.Traits import area_calc\n",
    "import utils.SegmentImage as SegmentImage\n",
    "import utils.Measure as Measure\n",
    "\n",
    "device = torch.device(GetLowestGPU(verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_kwargs = {\n",
    "    'layer_sizes': [32, 64, 128, 256, 512],\n",
    "    'in_channels': 3,\n",
    "    'out_channels': 4,\n",
    "    'conv_per_block': 3,\n",
    "    'dropout_rate': 0.1,\n",
    "    'hidden_activation': torch.nn.SELU(),\n",
    "    'output_activation': None,\n",
    "}\n",
    "\n",
    "unet = UNet(**model_kwargs)\n",
    "opt = torch.optim.AdamW(unet.parameters(), lr=1e-3)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find iteration with lowest loss\n",
    "log_path = '../logs/'\n",
    "log = pd.read_csv(log_path + 'log.csv')\n",
    "best_loss = log.iloc[log[\"val_loss\"].idxmin()][\"iter_num\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (hidden_activation): SELU()\n",
       "  (enc_layers): ModuleList(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SELU()\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): SELU()\n",
       "    (7): Dropout2d(p=0.1, inplace=False)\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): SELU()\n",
       "    (11): Dropout2d(p=0.1, inplace=False)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (13): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): SELU()\n",
       "    (16): Dropout2d(p=0.1, inplace=False)\n",
       "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): SELU()\n",
       "    (20): Dropout2d(p=0.1, inplace=False)\n",
       "    (21): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): SELU()\n",
       "    (24): Dropout2d(p=0.1, inplace=False)\n",
       "    (25): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (26): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (28): SELU()\n",
       "    (29): Dropout2d(p=0.1, inplace=False)\n",
       "    (30): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): SELU()\n",
       "    (33): Dropout2d(p=0.1, inplace=False)\n",
       "    (34): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): SELU()\n",
       "    (37): Dropout2d(p=0.1, inplace=False)\n",
       "    (38): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (39): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (40): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (41): SELU()\n",
       "    (42): Dropout2d(p=0.1, inplace=False)\n",
       "    (43): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): SELU()\n",
       "    (46): Dropout2d(p=0.1, inplace=False)\n",
       "    (47): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (48): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (49): SELU()\n",
       "    (50): Dropout2d(p=0.1, inplace=False)\n",
       "    (51): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (bottleneck_layers): ModuleList(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SELU()\n",
       "    (3): Dropout2d(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): SELU()\n",
       "    (7): Dropout2d(p=0.1, inplace=False)\n",
       "    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): SELU()\n",
       "    (11): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_layers): ModuleList(\n",
       "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (1-2): 2 x Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): SELU()\n",
       "    (5): Dropout2d(p=0.1, inplace=False)\n",
       "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): SELU()\n",
       "    (9): Dropout2d(p=0.1, inplace=False)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): SELU()\n",
       "    (13): Dropout2d(p=0.1, inplace=False)\n",
       "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (15-16): 2 x Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): SELU()\n",
       "    (19): Dropout2d(p=0.1, inplace=False)\n",
       "    (20): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): SELU()\n",
       "    (23): Dropout2d(p=0.1, inplace=False)\n",
       "    (24): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): SELU()\n",
       "    (27): Dropout2d(p=0.1, inplace=False)\n",
       "    (28): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (29-30): 2 x Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): SELU()\n",
       "    (33): Dropout2d(p=0.1, inplace=False)\n",
       "    (34): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): SELU()\n",
       "    (37): Dropout2d(p=0.1, inplace=False)\n",
       "    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (40): SELU()\n",
       "    (41): Dropout2d(p=0.1, inplace=False)\n",
       "    (42): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (43-44): 2 x Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (46): SELU()\n",
       "    (47): Dropout2d(p=0.1, inplace=False)\n",
       "    (48): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (50): SELU()\n",
       "    (51): Dropout2d(p=0.1, inplace=False)\n",
       "    (52): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (54): SELU()\n",
       "    (55): Dropout2d(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (final_activation): Identity()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights\n",
    "checkpoint = torch.load(f\"../checkpoints/checkpoint_{best_loss}.pt\", map_location=device)\n",
    "\n",
    "#extract weights from checkpoint\n",
    "weights = checkpoint[\"model\"]\n",
    "# trained model has been loaded\n",
    "unet.load_state_dict(weights)\n",
    "unet.eval()#inference mode (no dropout, batch norm uses running mean, etc.)\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in images\n",
    "# options\n",
    "image_path = \"../data/test/test_images/\"\n",
    "save_path = \"../data/pop_scale/pop_scale_segmentations/\"\n",
    "\n",
    "# load image data\n",
    "image_names = glob.glob(image_path + \"*.png\")\n",
    "image_names = [os.path.basename(x) for x in image_names]\n",
    "\n",
    "# remove image names that are already segmented\n",
    "segmented_images = glob.glob(save_path + \"*.png\")\n",
    "segmented_images = [re.sub(\"pred_\", \"\", os.path.basename(x)) for x in segmented_images]\n",
    "image_names = [x for x in image_names if x not in segmented_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images segmented:719 | Images to segment: 48\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images segmented:{len(segmented_images)} | Images to segment: {len(image_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 552-ref-950253-rep_1-M.png | Image 130 of 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec81576569b84eb1badcc6b1774e97cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run population scale prediction\n",
    "reload(SegmentImage)\n",
    "SegmentImage.segment_image(model = unet,\n",
    "                           image_names = image_names,\n",
    "                           image_path = image_path,\n",
    "                           mask_path = None,\n",
    "                           save_path = save_path,\n",
    "                           plot = False,\n",
    "                           verbose = 2,\n",
    "                           device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
