{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from DGXutils import GetFileNames, GetLowestGPU\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.Metrics import iou\n",
    "from utils.Preprocessing import split_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Significance Between Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy per image for each model\n",
    "base_path = '../data/test/{}_test_predictions_by_pod/'\n",
    "\n",
    "vanilla_path = base_path.format('vanilla')\n",
    "up_path = base_path.format('up')\n",
    "down_path = base_path.format('down')\n",
    "\n",
    "gt_path = '../data/test/test_masks_by_pod/'\n",
    "\n",
    "# only need one set of names since they are the same for all models\n",
    "gt_names = GetFileNames(gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0807b510594f41f3b7cd4414f7410480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "vanilla_preds, up_preds, down_preds, gt_masks = [], [], [], []\n",
    "\n",
    "print('Loading data...')\n",
    "for name in tqdm(gt_names):\n",
    "    # load\n",
    "    vanilla_pred = np.array(Image.open(vanilla_path + 'pred_' + name)) / 255\n",
    "    up_pred = np.array(Image.open(up_path + 'pred_' + name)) / 255\n",
    "    down_pred = np.array(Image.open(down_path + 'pred_' + name)) / 255\n",
    "\n",
    "    # turn bg to black\n",
    "    vanilla_pred[vanilla_pred.sum(axis=2) == 3] = 0\n",
    "    up_pred[up_pred.sum(axis=2) == 3] = 0\n",
    "    down_pred[down_pred.sum(axis=2) == 3] = 0\n",
    "\n",
    "    # append\n",
    "    vanilla_preds.append(vanilla_pred)\n",
    "    up_preds.append(up_pred)\n",
    "    down_preds.append(down_pred)\n",
    "\n",
    "    gt_masks.append(np.array(Image.open(gt_path + name)) / 255)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracies...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436784f4c6744cabaa57964953d02461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# get accuracies for each model\n",
    "vanilla_seed_acc, up_seed_acc, down_seed_acc = [], [], []\n",
    "\n",
    "print(\"Calculating accuracies...\")\n",
    "for i in tqdm(range(len(gt_masks))):\n",
    "    vanilla, up, down, mask = vanilla_preds[i], up_preds[i], down_preds[i], gt_masks[i]\n",
    "\n",
    "    vanilla_seed = vanilla[:, :, 2]\n",
    "    up_seed = up[:, :, 2]\n",
    "    down_seed = down[:, :, 2]\n",
    "    mask_seed = mask[:, :, 2]\n",
    "\n",
    "    vanilla_seed_acc.append(iou(vanilla_seed, mask_seed))\n",
    "    up_seed_acc.append(iou(up_seed, mask_seed))\n",
    "    down_seed_acc.append(iou(down_seed, mask_seed))\n",
    "print(\"Done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7692997804533273, 0.7666305824958907, 0.7718830387601895)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vanilla_seed_acc).mean(), np.array(up_seed_acc).mean(), np.array(down_seed_acc).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed Model Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "seed_df = pd.DataFrame({\n",
    "    'vanilla': vanilla_seed_acc,\n",
    "    'upweighted': up_seed_acc,\n",
    "    'downweighted': down_seed_acc\n",
    "})\n",
    "seed_df_melt = pd.melt(seed_df.reset_index(), id_vars=['index'], value_vars=['vanilla', 'upweighted', 'downweighted'])\n",
    "seed_df_melt.columns = ['index', 'treatments', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq     df         F    PR(>F)\n",
      "C(treatments)  0.000883    2.0  0.035066  0.965548\n",
      "Residual       2.379375  189.0       NaN       NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run ANOVA\n",
    "model = ols('value ~ C(treatments)', data=seed_df_melt).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Multiple Comparison of Means - Tukey HSD, FWER=0.05     \n",
      "=============================================================\n",
      "   group1      group2   meandiff p-adj   lower  upper  reject\n",
      "-------------------------------------------------------------\n",
      "downweighted upweighted  -0.0053 0.9621 -0.0521 0.0416  False\n",
      "downweighted    vanilla  -0.0026 0.9907 -0.0494 0.0443  False\n",
      "  upweighted    vanilla   0.0027 0.9901 -0.0442 0.0495  False\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# run tukey HSD test\n",
    "m_comp = pairwise_tukeyhsd(endog=seed_df_melt['value'], groups=seed_df_melt['treatments'], alpha=0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model v. Human Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy per image for each model\n",
    "out_path = '../data/human_eval_by_pod/'\n",
    "john_path = out_path + 'john/490-ref-ISU_073-rep_1-W - JL_{}.png'\n",
    "bill_path = out_path + 'bill/BILL_490-ref-ISU_073-rep_1-W_{}.png'\n",
    "roshan_path = out_path + 'roshan/CRA_outline_{}.png'\n",
    "pete_path = out_path + 'pete/pete_490-ref-ISU_073-rep_1-W_{}.png'\n",
    "avg_path = out_path + 'avg/avg_pred_{}.png'\n",
    "\n",
    "model_path = '/mnt/DGX01/Personal/krusepi/codebase/projects/phenotyping/PennycressUNet/data/test/vanilla_test_predictions_by_pod/pred_490-ref-ISU_073-rep_1-W_{}.png'\n",
    "\n",
    "# only need one set of names since they are the same for all models\n",
    "names = GetFileNames(pete_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "model_preds, john_preds, bill_preds, pete_preds, roshan_preds = [], [], [], [], []\n",
    "\n",
    "print('Loading data...')\n",
    "for i in tqdm(len(names)):\n",
    "    # load\n",
    "    model_pred = np.array(Image.open(model_path.format(i))) / 255\n",
    "    john_pred = np.array(Image.open(john_path.format(i))) / 255\n",
    "    bill_pred = np.array(Image.open(bill_path.format(i))) / 255\n",
    "    pete_pred = np.array(Image.open(pete_path.format(i))) / 255\n",
    "    roshan_pred = np.array(Image.open(roshan_path.format_i)) / 255\n",
    "    avg_pred = \n",
    "    \n",
    "    # turn bg to black\n",
    "    model_pred[model_pred.sum(axis=2) == 3] = 0\n",
    "    john_pred[john_pred.sum(axis=2) == 3] = 0\n",
    "    bill_pred[bill_pred.sum(axis=2) == 3] = 0\n",
    "    pete_pred[pete_pred.sum(axis=2) == 3] = 0\n",
    "    roshan_pred[roshan_pred.sum(axis=2) == 3] = 0\n",
    "\n",
    "    # append\n",
    "    model_preds.append(vanilla_pred)\n",
    "    john_preds.append(up_pred)\n",
    "    bill_preds.append(down_pred)\n",
    "\n",
    "    gt_masks.append(np.array(Image.open(gt_path + name)) / 255)\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
