{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. Take in full image as input\n",
    "2. Pad image by 32 px on all sides\n",
    "3. Ensure that image is a multiple of 128 x 128 by adding extra padding\n",
    "4. initialize global probability map which is same spatial (h x w) size as input image with one channel for every class\n",
    "\n",
    "# Bookkeeping\n",
    "1. Double for loop over rows and columns with step size of 32 used for tile generation\n",
    "2. Track indices between global and local images \n",
    "3. Add probabilities to global mask in corresponding location\n",
    "4. Normalize probabilities in mask by dividing *[H x W x C] / [H x W x sum(C)]* (Taking advantage of softmax)\n",
    "5. Take the argmax of each px. channelwise and return class predictions\n",
    "6. Compare prediction with GT using  IOU/other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "# create U-Net class inheriting from torch.nn.Module\n",
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                enc_layer_sizes = [16, 32, 64, 128],\n",
    "                dec_layer_sizes = [128, 64, 32, 16],\n",
    "                in_channels=3,\n",
    "                out_channels=4,\n",
    "                dropout_rate=0.1,\n",
    "                conv_per_block=1):\n",
    "\n",
    "        super().__init__() #inherit attrs. from Module\n",
    "\n",
    "        self.enc_layer_sizes = enc_layer_sizes\n",
    "        self.dec_layer_sizes = dec_layer_sizes\n",
    "        self.num_enc_layers = len(enc_layer_sizes)\n",
    "        self.num_dec_layers = len(dec_layer_sizes)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = 3\n",
    "        self.padding = 1\n",
    "        self.dropout_rate=dropout_rate\n",
    "        self.conv_per_block=conv_per_block\n",
    "\n",
    "        # create lists to hold each layer group\n",
    "        self.enc_layers = torch.nn.ModuleList()\n",
    "        self.bottleneck_layers = torch.nn.ModuleList()\n",
    "        self.dec_layers = torch.nn.ModuleList()\n",
    "\n",
    "        # create encoder blocks\n",
    "        for i in range(self.num_enc_layers-1):\n",
    "            if i == 0:\n",
    "                self.enc_layers += self.enc_layer(self.in_channels, self.enc_layer_sizes[i], self.kernel_size, self.padding)\n",
    "            else:\n",
    "                self.enc_layers += self.enc_layer(self.enc_layer_sizes[i-1], self.enc_layer_sizes[i], self.kernel_size, self.padding)\n",
    "\n",
    "        # create bottleneck block        \n",
    "        self.bottleneck_layers += self.enc_layer(self.enc_layer_sizes[-2], self.enc_layer_sizes[-1], self.kernel_size, self.padding, pool=False)\n",
    "\n",
    "        # create decoder blocks\n",
    "        for i in range((self.num_dec_layers-1)):\n",
    "            self.dec_layers += self.dec_layer(self.dec_layer_sizes[i], self.dec_layer_sizes[i+1], self.kernel_size, self.padding)\n",
    "\n",
    "        # add final layer\n",
    "        self.final_layer = torch.nn.Conv2d(self.dec_layer_sizes[-1], out_channels, kernel_size=1, padding=0)\n",
    "        self.final_activation = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "        \n",
    "        conv_block = torch.nn.Sequential()\n",
    "        for i in range(self.conv_per_block):\n",
    "\n",
    "            if i == 0:\n",
    "                conv_block += torch.nn.Sequential(torch.nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    padding=self.padding),\n",
    "                torch.nn.BatchNorm2d(out_channels),\n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Dropout2d(self.dropout_rate)\n",
    "                )\n",
    "            else:\n",
    "                # define base conv_block structure\n",
    "                conv_block += torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(\n",
    "                        in_channels=out_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=self.kernel_size,\n",
    "                        padding=self.padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.LeakyReLU(),\n",
    "                    torch.nn.Dropout2d(self.dropout_rate)\n",
    "                )\n",
    "        return conv_block\n",
    "    \n",
    "    def enc_layer(self, in_channels, out_channels, kernel_size, padding, pool=True):\n",
    "\n",
    "        # define encoder layer structure\n",
    "        enc_layer = self.conv_block(in_channels,\n",
    "                                    out_channels,\n",
    "                                    kernel_size=self.kernel_size, \n",
    "                                    padding=self.padding)\n",
    "        if pool == True:\n",
    "            enc_layer.append(torch.nn.MaxPool2d(2))\n",
    "\n",
    "        return enc_layer\n",
    "\n",
    "    def dec_layer(self, in_channels, out_channels, kernel_size, padding, upsample=True):\n",
    "\n",
    "        # define decoder layer structure\n",
    "        if upsample == True:\n",
    "            upsample = torch.nn.Sequential(\n",
    "                torch.nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                torch.nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=self.kernel_size,\n",
    "                    padding=self.padding)\n",
    "            )\n",
    "            #prepend upsampling layer to conv_block to make decoder\n",
    "            dec_layer = upsample + self.conv_block(in_channels, \n",
    "                                                    out_channels, \n",
    "                                                    self.kernel_size, \n",
    "                                                    self.padding)\n",
    "\n",
    "        else:\n",
    "            dec_layer = self.conv_block(in_channels, out_channels, self.kernel_size, self.padding)\n",
    "\n",
    "        return dec_layer\n",
    "\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "        \n",
    "        cache = []\n",
    "        #propagate through encoder layers\n",
    "        for i, enc_layer in enumerate(self.enc_layers):\n",
    "            x = enc_layer(x)\n",
    "            if (i+1) % 5 == 4: #5 layers per encoder block; on the 4th layer, save output in cache\n",
    "                cache.append(x) #save layer outputs in cache for skip connections\n",
    "\n",
    "        #propagate through bottleneck layer\n",
    "        for bottleneck_layer in self.bottleneck_layers:\n",
    "            x = bottleneck_layer(x)\n",
    "\n",
    "        #propagate through decoder layers\n",
    "        j = 0 # set index control var for cache\n",
    "        for i, dec_layer in enumerate(self.dec_layers):\n",
    "            x = dec_layer(x)\n",
    "            if (i+1) % 6 == 2: # 6 layers per decoder block; on the 2nd layer, concatenate with cache\n",
    "                x = torch.cat([x, cache[-(j+1)]], dim=1)\n",
    "                j += 1\n",
    "\n",
    "        #apply final conv layer\n",
    "        x = self.final_layer(x)\n",
    "        x = self.final_activation(x)\n",
    "        return x\n",
    "\n",
    "# create model \n",
    "unet = UNet(enc_layer_sizes=[16, 32, 64, 128],\n",
    "            dec_layer_sizes=[128, 64, 32, 16],\n",
    "            in_channels=3,\n",
    "            out_channels=4,\n",
    "            conv_per_block=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"enc_layers.0.weight\", \"enc_layers.0.bias\", \"enc_layers.1.weight\", \"enc_layers.1.bias\", \"enc_layers.1.running_mean\", \"enc_layers.1.running_var\", \"enc_layers.5.weight\", \"enc_layers.5.bias\", \"enc_layers.6.weight\", \"enc_layers.6.bias\", \"enc_layers.6.running_mean\", \"enc_layers.6.running_var\", \"enc_layers.10.weight\", \"enc_layers.10.bias\", \"enc_layers.11.weight\", \"enc_layers.11.bias\", \"enc_layers.11.running_mean\", \"enc_layers.11.running_var\", \"bottleneck_layers.0.weight\", \"bottleneck_layers.0.bias\", \"bottleneck_layers.1.weight\", \"bottleneck_layers.1.bias\", \"bottleneck_layers.1.running_mean\", \"bottleneck_layers.1.running_var\", \"dec_layers.1.weight\", \"dec_layers.1.bias\", \"dec_layers.2.weight\", \"dec_layers.2.bias\", \"dec_layers.3.weight\", \"dec_layers.3.bias\", \"dec_layers.3.running_mean\", \"dec_layers.3.running_var\", \"dec_layers.7.weight\", \"dec_layers.7.bias\", \"dec_layers.8.weight\", \"dec_layers.8.bias\", \"dec_layers.9.weight\", \"dec_layers.9.bias\", \"dec_layers.9.running_mean\", \"dec_layers.9.running_var\", \"dec_layers.13.weight\", \"dec_layers.13.bias\", \"dec_layers.14.weight\", \"dec_layers.14.bias\", \"dec_layers.15.weight\", \"dec_layers.15.bias\", \"dec_layers.15.running_mean\", \"dec_layers.15.running_var\", \"final_layer.weight\", \"final_layer.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"optimizer\", \"iter_num\", \"best_val_loss\", \"train_ids\", \"val_ids\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load model weights\u001b[39;00m\n\u001b[1;32m      2\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m../weights/checkpoint_4000.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m unet\u001b[39m.\u001b[39;49mload_state_dict(weights)\n\u001b[1;32m      5\u001b[0m unet\u001b[39m.\u001b[39meval() \u001b[39m#inference mode (no dropout, batch norm uses running mean, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/proj/my_env/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"enc_layers.0.weight\", \"enc_layers.0.bias\", \"enc_layers.1.weight\", \"enc_layers.1.bias\", \"enc_layers.1.running_mean\", \"enc_layers.1.running_var\", \"enc_layers.5.weight\", \"enc_layers.5.bias\", \"enc_layers.6.weight\", \"enc_layers.6.bias\", \"enc_layers.6.running_mean\", \"enc_layers.6.running_var\", \"enc_layers.10.weight\", \"enc_layers.10.bias\", \"enc_layers.11.weight\", \"enc_layers.11.bias\", \"enc_layers.11.running_mean\", \"enc_layers.11.running_var\", \"bottleneck_layers.0.weight\", \"bottleneck_layers.0.bias\", \"bottleneck_layers.1.weight\", \"bottleneck_layers.1.bias\", \"bottleneck_layers.1.running_mean\", \"bottleneck_layers.1.running_var\", \"dec_layers.1.weight\", \"dec_layers.1.bias\", \"dec_layers.2.weight\", \"dec_layers.2.bias\", \"dec_layers.3.weight\", \"dec_layers.3.bias\", \"dec_layers.3.running_mean\", \"dec_layers.3.running_var\", \"dec_layers.7.weight\", \"dec_layers.7.bias\", \"dec_layers.8.weight\", \"dec_layers.8.bias\", \"dec_layers.9.weight\", \"dec_layers.9.bias\", \"dec_layers.9.running_mean\", \"dec_layers.9.running_var\", \"dec_layers.13.weight\", \"dec_layers.13.bias\", \"dec_layers.14.weight\", \"dec_layers.14.bias\", \"dec_layers.15.weight\", \"dec_layers.15.bias\", \"dec_layers.15.running_mean\", \"dec_layers.15.running_var\", \"final_layer.weight\", \"final_layer.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"optimizer\", \"iter_num\", \"best_val_loss\", \"train_ids\", \"val_ids\". "
     ]
    }
   ],
   "source": [
    "# load model weights\n",
    "weights = torch.load(\"../weights/checkpoint_4000.pt\")\n",
    "\n",
    "unet.load_state_dict(weights)\n",
    "unet.eval() #inference mode (no dropout, batch norm uses running mean, etc.)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
